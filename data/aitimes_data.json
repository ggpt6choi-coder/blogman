[
  {
    "date": "2025-10-22T18:00:00+09:00",
    "title": "앤트로픽, 오픈AI 추격 위해 구글과 수백억달러 컴퓨팅 계약 논의",
    "article": "앤트로픽이 구글과 추가 컴퓨팅 파워 제공 협상을 진행 중인 것으로 알려졌다. '스타게이트'로 대규모 컴퓨팅 용량을 확보한 오픈AI 추격전에 나선 것이다.\n블룸버그는 21일(현지시간) 정통한 소식통을 인용, 앤트로픽이 구글과 수백억 달러 규모의 컴퓨팅 파워 협상을 진행 중이라고 보도했다.\n협상은 구글이 앤트로픽에 클라우드 컴퓨팅 서비스를 제공하는 방식으로 진행되는 것으로 전해졌다. 구글은 과거에도 앤트로픽의 투자자이자 클라우드 서비스 제공업체로 협력 관계를 유지해 왔다.\n양사는 이번 사안에 대해 공식 입장을 내놓지 않았으며, 협상은 아직 초기 단계라 조건이 변경될 가능성도 있다.\n이 소식이 알려진 직후 구글 주가는 시간 외 거래에서 3.5% 이상 상승했지만, 앤트로픽 투자자이자 클라우드 제공업체인 아마존 주가는 약 2% 하락했다.\n앤트로픽은 오픈AI와의 경쟁에서 밀리지 않기 위해 대규모 자금 유치와 컴퓨팅 자원 확보에 적극적으 나서고 있다. 최근에는 아랍에미리트(UAE) 투자사 MGX와 초기 펀딩 협상을 진행했는데, 이는 한달 전 마무리된 130억달러(약 18조원)의 투자 라운드 직후 이뤄진 것이다.\n앞서 지난 6월에는 아마존이 앤트로픽을 위한 대규모 데이터센터 '프로젝트 레이니어'를 구축 중이라는 소식도 전해졌다. 이곳은 2.2기가와트(GW)급으로 알려졌다.\n오픈AI는 엔비디어, AMD, 오라클 등과의 계약을 통해 26GW에 달하는 데이터센터를 구축하겠다고 밝혔다.\n한편, 구글은 2023년 20억달러에 이어 올해 초 10억달러를 추가 투자하는 등 몇차례에 걸쳐 앤트로픽에 자금을 지원했다.\n아마존도 앤트로픽에 최대 80억달러를 투자하겠다고 밝혔다. 앤트로픽은 AWS의 핵심 고객이자 아마존 맞춤형 AI 칩의 주요 사용자다.\n박찬 기자 cpark@aitimes.com",
    "link": "https://www.aitimes.com/news/articleView.html?idxno=203334",
    "type": "AITIMES",
    "newTitle": "앤트로픽 구글과 컴퓨팅 파워 확보 협상 오픈AI 경쟁 치열",
    "newArticle": [
      {
        "title": "앤트로픽, 구글과 컴퓨팅 협상",
        "content": "AI 스타트업 앤트로픽이 거대 IT 기업 구글과 대규모 컴퓨팅 파워 확보를 위한 협상을 진행 중이라는 소식이 전해지며 업계의 이목이 집중되고 있습니다. 블룸버그 통신은 익명의 소식통을 인용하여 앤트로픽이 구글로부터 수백억 달러 규모의 클라우드 컴퓨팅 서비스를 제공받는 방안을 논의 중이라고 보도했습니다. 이는 인공지능 분야의 선두 주자인 오픈AI와의 치열한 경쟁 속에서 앤트로픽이 컴퓨팅 자원 확보에 사활을 걸고 있음을 보여줍니다. 구글은 과거에도 앤트로픽의 주요 투자자이자 클라우드 서비스 공급업체로서 긴밀한 협력 관계를 유지해왔기에, 이번 협상이 성사될 경우 양사 간의 파트너십은 더욱 공고해질 것으로 예상됩니다. 다만, 현재 협상은 초기 단계에 있으며 구체적인 조건은 변경될 가능성이 있습니다. 앤트로픽의 컴퓨팅 능력 강화는 AI 모델 개발 및 서비스 확장에 필수적인 요소로, 이번 협상은 앤트로픽의 성장 전략에 있어 중요한 변곡점이 될 수 있습니다. 앤트로픽의 컴퓨팅 파워 증가는 AI 기술 발전의 속도를 더욱 가속화시킬 것으로 기대됩니다."
      },
      {
        "title": "AI 경쟁 심화, 컴퓨팅 파워 확보 경쟁",
        "content": "오픈AI가 '스타게이트' 프로젝트를 통해 막대한 컴퓨팅 용량을 확보하려는 움직임을 보이자, 앤트로픽 역시 이에 맞서 컴퓨팅 자원 확보에 적극적으로 나서고 있습니다. 앤트로픽은 경쟁사 오픈AI와의 격차를 줄이고자 대규모 자금 유치와 함께 필수적인 컴퓨팅 인프라 구축에 공을 들이고 있습니다. 최근 앤트로픽은 아랍에미리트(UAE)의 투자사 MGX와 초기 펀딩 협상을 진행했으며, 이는 한 달 전 마무리된 130억 달러(약 18조원) 규모의 투자 라운드 직후에 이루어진 것이어서 앤트로픽의 자금 조달 능력을 다시 한번 확인시켜 주었습니다. 또한, 앞서 6월에는 아마존이 앤트로픽을 위해 2.2기가와트(GW)급 대규모 데이터센터 '프로젝트 레이니어'를 구축 중이라는 소식도 전해진 바 있습니다. 이는 앤트로픽이 단순히 클라우드 서비스를 이용하는 것을 넘어 자체적인 컴퓨팅 인프라를 확장하려는 의지를 보여주는 대목입니다. 이러한 앤트로픽의 움직임은 AI 기술 경쟁이 단순히 모델 성능 싸움을 넘어, 이를 뒷받침하는 강력한 컴퓨팅 파워 확보 경쟁으로 심화되고 있음을 시사합니다."
      },
      {
        "title": "오픈AI, 26GW 데이터센터 구축 계획",
        "content": "경쟁사인 오픈AI 역시 AI 기술 발전을 위한 컴퓨팅 인프라 구축에 박차를 가하고 있습니다. 오픈AI는 엔비디어, AMD, 오라클 등과의 협력을 통해 무려 26기가와트(GW)에 달하는 데이터센터를 구축하겠다는 야심찬 계획을 밝힌 바 있습니다. 이는 앤트로픽의 '프로젝트 레이니어' 규모를 훨씬 상회하는 것으로, 오픈AI가 AI 분야에서의 압도적인 우위를 유지하기 위해 투자를 아끼지 않고 있음을 보여줍니다. 26GW라는 막대한 컴퓨팅 용량은 현재 상용화된 AI 모델뿐만 아니라, 미래에 등장할 더욱 발전된 AI 모델들을 훈련하고 운영하는 데 필요한 필수적인 자원입니다. 오픈AI의 이러한 대규모 인프라 투자는 AI 연구 개발의 속도를 비약적으로 높이고, 새로운 AI 서비스의 출시를 앞당길 수 있는 원동력이 될 것입니다. 앤트로픽을 비롯한 다른 AI 스타트업들은 이러한 오픈AI의 공격적인 행보에 대응하기 위해 더욱 효율적인 컴퓨팅 자원 활용 방안과 전략적인 파트너십 모색에 집중해야 할 필요가 있습니다. AI 기술 경쟁은 컴퓨팅 파워 확보 경쟁으로 직결되며, 이는 곧 AI 시장의 판도를 결정짓는 중요한 요소가 될 것입니다."
      },
      {
        "title": "구글-아마존, 앤트로픽 투자 확대",
        "content": "구글과 아마존은 앤트로픽의 잠재력을 높이 평가하고 지속적으로 투자 및 지원을 확대하고 있습니다. 구글은 2023년에 20억 달러, 그리고 올해 초 추가로 10억 달러를 투자하는 등 여러 차례에 걸쳐 앤트로픽에 자금을 지원해왔습니다. 이러한 구글의 투자는 앤트로픽의 AI 모델 개발 및 상용화를 위한 중요한 기반이 되고 있습니다. 아마존 역시 앤트로픽에 최대 80억 달러를 투자하겠다는 의사를 밝혔습니다. 특히 앤트로픽은 아마존의 클라우드 서비스인 AWS의 핵심 고객 중 하나이며, 아마존이 자체 개발한 AI 칩의 주요 사용자이기도 합니다. 이는 앤트로픽과 아마존 간의 파트너십이 단순한 투자를 넘어 기술적인 시너지 창출로 이어지고 있음을 의미합니다. 구글과 아마존이 앤트로픽에 대한 투자를 지속적으로 늘리는 이유는 AI 시장의 성장 가능성과 앤트로픽의 기술 경쟁력을 높이 평가하기 때문입니다. 앤트로픽이 구글의 컴퓨팅 파워를 확보하고, 아마존과의 협력을 강화하면서 AI 분야에서의 입지를 더욱 다질 것으로 예상됩니다."
      },
      {
        "title": "개인적인 생각",
        "content": "앤트로픽의 구글과의 컴퓨팅 파워 협상 소식은 AI 시장의 극심한 경쟁과 그 속에서 살아남기 위한 기업들의 치열한 노력을 여실히 보여줍니다. 특히 오픈AI의 '스타게이트'와 같은 거대한 프로젝트와 비교될 때, 앤트로픽이 컴퓨팅 자원 확보에 얼마나 필사적인지를 알 수 있습니다. 구글이 앤트로픽에 대한 투자를 늘리고 클라우드 컴퓨팅 파워까지 제공하려 하는 것은, 앤트로픽의 성장 가능성에 대한 확신과 함께 AI 생태계에서의 영향력을 강화하려는 전략으로 해석됩니다. 반면, 아마존 주가가 하락한 것은 단기적인 관점에서 다른 투자 기회나 실적에 대한 우려를 반영할 수도 있겠지만, 장기적으로는 앤트로픽과의 전략적 파트너십을 더욱 강화할 가능성이 높습니다. AI 기술 경쟁은 이미 모델 성능을 넘어 인프라, 즉 컴퓨팅 파워 확보로 확장되었습니다. 26GW라는 오픈AI의 데이터센터 구축 계획은 AI 기술의 미래가 얼마나 막대한 컴퓨팅 자원을 요구하는지를 명확히 보여줍니다. 앤트로픽이 구글과의 협상을 통해 이 격차를 얼마나 좁힐 수 있을지가 향후 AI 시장의 판도를 가르는 중요한 변수가 될 것입니다. 이는 결국 AI 서비스의 접근성과 혁신의 속도에 직접적인 영향을 미칠 것이며, AI 기술의 민주화와 발전에 있어 중요한 시사점을 던져줍니다. 앤트로픽이 이러한 경쟁 속에서 성공적으로 컴퓨팅 능력을 확보하고 기술 발전을 이끌어 나갈 수 있을지 주목해야 합니다."
      }
    ],
    "hashTag": [
      "#앤트로픽",
      "#구글",
      "#AI경쟁",
      "#오픈AI",
      "#클라우드컴퓨팅",
      "#스타게이트",
      "#AI반도체",
      "#데이터센터",
      "#AI투자",
      "#MGX"
    ]
  },
  {
    "date": "2025-10-22T18:00:00+09:00",
    "title": "실리콘 밸리에 퍼져 나가는 '996' 근무제...\"2~3년내 성공해야\"",
    "article": "실리콘 밸리 스타트업들이 '996', 즉 오전 9시부터 오후 9시까지 주 6일 근무하는 하드코어 문화를 잇달아 도입하고 있다는 소식이다. 인공지능(AI)이 불러온 기회와 치열한 경쟁으로, 앞으로 2~3년 안에 성공해야 한다는 절박함이 반영됐다는 분석이다.\n워싱턴 포스트는 20일(현지시간) AI 분야에서 앞서나가기 위한 경쟁이 치열해 짐에 따라, 실리콘 밸리 스타트업들이 주 72시간 근무제를 선호한다고 소개했다. 이를 '그라인드(Grind)' 문화라고 불렀다.\n대표적인 곳은 강도 높은 업무로 유명한 코딩 스타트업 코그니션이다. 이 회사는 채용 공고에도 이를 공개적으로 밝히고 있다.\n스콧 우 CEO는 얼마 전 인수한 윈드서프 직원들에게도 장시간 근무를 할 준비가 되어 있어야 한다고 밝혔다. X(트위터)를 통해 \"코그니션은 극단적인 성과 중심 문화를 가지고 있으며, 채용 과정에서 이 점을 미리 알려서 나중에 예상치 못한 일이 없도록 한다\"라며 \"우리는 업무 방식에 자부심을 느끼지만, 모든 사람에게 적합한 것은 아니라는 점을 잘 알고 있다\"라고 말했다.\nAI 라벨링 전문 메르코(Mercor)도 최근 채용 공고를 게재하며, 지원자는 주 6일 근무할 의향이 있어야 하며 이는 협상의 여지가 없다고 밝혔다.\n996은 마윈 알리바바 회장이 강조하며 2010년대 중국에서 유행했던 근무 행태다. 하지만 극심한 번아웃과 과로로 부작용이 호소되고 일부가 사망하자, 중국 정부는 이를 법으로 금지했다.\n성공을 위해 실리콘 밸리로 몰려든 미국의 젊은 창업자들이 올해 초부터 이를 새로운 성공 공식으로 받아들였다는 이야기는 이미 전해진 바 있다. 이제는 기업 전체의 문화로 자리 잡는 단계라는 것이다.\n이는 치열한 경쟁이 펼쳐지는 AI 분야에서 살아남기 위한 것이라는 설명이다. 캘로라인 위넷 버클리 스카이덱 전무는 \"생성 AI 덕분에 거대 기업이 탄생할 것이라는 사실은 누구나 알고 있다\"라며 \"그래서 스타트업은 모두가 하나가 되자며 더 열심히 일한다\"라고 말했다.\n실제로 이런 스타트업 중 상당수는 초기 멤버 몇명이 포진한 곳으로, 이곳의 직원들은 일반 회사와는 다르다. 회사가 성공하면 큰 돈을 만질 수 있다.\n벤처 캐피털 라이프X 벤처스의 이나키 베렝게르 파트너는 \"AI를 먼저 개발하는 사람이 시장을 장악하게 될 것이며, 기회는 2~3년뿐\"이라며 \"다른 사람보다 더 빨리 달려야 한다\"라고 말했다.\n이를 즐긴다는 사람도 있다. AI 스타트업을 운영하는 24세의 매그너스 뮐러 CEO는 토요일과 일요일을 포함해 24시간 내내 일한다고 밝혔다. 그는 \"사람들이 일로 치부하는 일들을 나는 대부분 일로 여기지 않는다\"라며 \"마치 비디오 게임을 하는 것과 같다. 하루 종일 할 수 있는 일이다\"라고 말했다.\n이들 스타트업이 무턱대고 야근을 요구하는 것은 아니라는 설명이다. AI 스타트업 소나틱은 하루 10시간 주 7일 근무를 요구하지만, 무료 숙박과 음식 배달, 데이팅 서비스 구독 등의 혜택을 제공한다. 자잘한 집안일에 신경 쓸 필요가 없기 때문에 시간을 잘 활용하면 헬스나 취미 생활도 가능하다고 밝혔다.\n또 옵티멀 AI라는 스타트업은 996 원칙을 반드시 따라야 하지만, 직원들의 근무 시간은 유연하게 조절할 수 있다고 전했다. 주요 제품 출시를 앞두고 크런치 모드에 돌입할 때 근무 시간을 집중 투입, 이제는 자연스럽게 운영된다고 소개했다.\n이런 분위기를 반영하듯, 한 벤처캐피털 파트너는 최근 X를 통해 '그라인드 스코어'를 올려 화제가 됐다. 자레드 슬리퍼 애버니어 파트너는 '그라인드=긍정적인 사업 전망'이라고 표현했다. 여기에는 어플라이드 인튜이션이나 쉴드 AI, 피그마 등 유명 스타트업들이 포함돼 있다.\n하지만, 일부는 이런 문화를 미화하면 번아웃을 초래하고, 일할 의욕이 줄어들어 인재 풀이 제한된다고 지적한다.\n디디 다스 멘로벤처스 파트너는 긴 근무 일정이 일하는 것보다 일을 미루는 습관을 더 키우는 경우가 많다며, 더 창의적인 일을 하려면 뇌가 활력을 되찾아야 한다고 강조했다.\n\"이런 것을 미화하려는 창업자들은 대부분 젊은 편이라고 생각한다\"라며 \"경험자들은 주 40~50시간 일해도 주 80시간 일하는 사람들보다 훨씬 더 많은 일을 해낼 수 있다는 사실을 이해할 만큼 성숙하지 못한 것\"이라고 지적했다.\n또 이런 방침을 내세우는 회사의 게시물에는 \"996은 생명이 없는 노예\"라는 댓글도 남았다.\n하지만 일부 창립자는 채용 공고에 996을 포함하면 \"자신이 하는 일에 진정으로 집착하는 사람들을 끌어들일 수 있다\"라고 말했다.\nAI 스타트업 에덱시아의 다니엘 기번 CEO는 팀원들이 지치거나 아프지 않고 자신의 한계를 뛰어넘는 법을 배우는 것이 중요하다고 말했다. \"정신적, 신체적 건강을 포함한 모든 것을 최적화한다면, 몸을 꽤 밀어붙일 수 있다\"라고 말했다.\n임대준 기자 ydj@aitimes.com",
    "link": "https://www.aitimes.com/news/articleView.html?idxno=203347",
    "type": "AITIMES",
    "newTitle": "실리콘밸리 AI 스타트업들의 주 6일 근무 문화 이유는",
    "newArticle": [
      {
        "title": "AI 시대, 996 열풍",
        "content": "최근 실리콘 밸리 스타트업들 사이에서 '996'으로 불리는 주 6일, 오전 9시부터 오후 9시까지 근무하는 극한의 업무 문화가 다시금 확산되고 있다는 소식입니다. 인공지능(AI) 기술 발전으로 인한 거대한 기회와 동시에 극심한 경쟁 환경이 이러한 절박함을 부추기고 있으며, 앞으로 2~3년 안에 승부를 봐야 한다는 위기감이 반영된 결과로 분석됩니다. 이러한 '그라인드(Grind)' 문화는 AI 분야에서 선두를 차지하기 위한 스타트업들의 치열한 생존 경쟁을 단적으로 보여주는 현상입니다. 코그니션과 메르코 같은 AI 스타트업들은 이미 채용 공고에 장시간 근무 의향을 명시하며 이러한 문화를 공개적으로 받아들이고 있습니다. 스콧 우 코그니션 CEO는 극단적인 성과 중심 문화를 강조하며, 직원들에게 장시간 근무를 할 준비가 되어 있어야 한다고 분명히 밝히고 있습니다. 이는 단순히 업무 강도를 높이는 것을 넘어, AI 시대의 빠른 변화 속에서 살아남기 위한 전략으로 볼 수 있습니다."
      },
      {
        "title": "생존 위한 '그라인드' 문화",
        "content": "AI 분야의 폭발적인 성장 가능성과 함께 경쟁이 심화되면서, 실리콘 밸리 스타트업들은 '그라인드'라고 불리는 주 72시간 근무제를 적극적으로 채택하고 있습니다. 이는 생성 AI 기술의 발전으로 인해 거대한 기업이 탄생할 것이라는 예측이 지배적인 가운데, 뒤처지지 않기 위한 스타트업들의 필사적인 노력의 일환입니다. 캘로라인 위넷 버클리 스카이덱 전무는 '모두가 하나가 되자'는 구호 아래 더욱 열심히 일하는 스타트업들의 분위기를 전하며, 이러한 '그라인드' 문화가 AI 분야의 특수성을 반영하고 있다고 설명합니다. 초기 멤버로 구성된 소규모 스타트업의 경우, 회사의 성공이 곧 개인의 큰 경제적 보상으로 이어질 수 있다는 기대감 또한 장시간 근무를 이끌어내는 요인으로 작용합니다. 벤처 캐피털 업계에서도 AI 시장 선점을 위해서는 '다른 사람보다 더 빨리 달려야 한다'는 인식이 팽배하며, 기회가 2~3년밖에 남지 않았다는 위기감이 이러한 '그라인드' 문화를 가속화시키고 있습니다. 이는 단순히 과도한 업무를 강요하는 것을 넘어, AI 시대의 빠른 흐름 속에서 성공을 거머쥐기 위한 불가피한 선택으로 여겨지고 있습니다."
      },
      {
        "title": "새로운 성공 공식? 996 분석",
        "content": "과거 2010년대 중국에서 마윈 알리바바 회장이 강조하며 유행했던 '996' 근무 방식이 이제 실리콘 밸리에서 새로운 성공 공식으로 주목받고 있습니다. 물론 996 문화는 극심한 번아웃과 과로로 인한 부작용으로 중국 정부에 의해 법적으로 금지되기도 했지만, 현재 실리콘 밸리의 젊은 창업자들은 이를 AI 시대의 성공을 위한 필수 전략으로 받아들이는 분위기입니다. 특히 AI 스타트업들은 초기 멤버 몇 명이 핵심적인 역할을 수행하는 경우가 많기 때문에, 이들의 헌신과 집중이 회사의 성공에 결정적인 영향을 미칩니다. 벤처 캐피털 라이프X 벤처스의 이나키 베렝게르 파트너는 AI 기술 개발 경쟁에서 앞서나가는 것이 시장을 장악하는 열쇠이며, 짧은 시간 안에 승부를 봐야 한다고 강조하며 이러한 '996' 문화의 배경을 설명합니다. AI 스타트업들은 '다른 사람보다 더 빨리 달려야 한다'는 절박함 속에서 '996'을 단순한 노동 강도 증가가 아닌, 급변하는 AI 시장에서 기회를 포착하기 위한 전략으로 인식하고 있습니다. 이는 AI 기술 발전이 가져온 새로운 시대적 흐름 속에서 기업들이 생존과 성장을 위해 선택할 수 있는 하나의 길이 되고 있습니다."
      },
      {
        "title": "워라밸 vs 성과, 딜레마",
        "content": "AI 스타트업들의 '996' 문화는 장밋빛 전망만 있는 것은 아닙니다. 일부에서는 이러한 문화를 미화하는 것이 장기적으로 번아웃을 유발하고 인재 풀을 제한할 수 있다고 지적합니다. 디디 다스 멘로벤처스 파트너는 긴 근무 일정이 오히려 일을 미루는 습관을 키우고, 창의적인 업무 수행을 위해서는 뇌의 휴식이 필수적이라고 강조합니다. 그는 젊은 창업자들이 주 40~50시간만 일해도 주 80시간 일하는 사람보다 더 많은 성과를 낼 수 있다는 점을 간과하고 있다고 비판합니다. 또한, '996' 문화에 대한 부정적인 시각도 존재하며, 이는 '생명이 없는 노예'라는 격렬한 비판으로 이어지기도 합니다. 이러한 비판 속에서도 일부 창업자들은 '996'을 통해 일에 대한 열정이 강한 인재를 선별하고, 자신의 한계를 뛰어넘는 경험을 통해 성장할 수 있다고 주장합니다. 이는 워라밸을 중시하는 현대 사회의 가치관과 성과 중심의 AI 스타트업 문화 사이의 첨예한 대립을 보여주며, 앞으로 이 문제가 어떻게 봉합될지 주목해야 할 부분입니다."
      },
      {
        "title": "개인적인 생각",
        "content": "AI 시대의 '996' 문화 확산은 분명 흥미로운 현상이지만, 동시에 여러 가지 질문을 던집니다. '그라인드' 문화가 단기적인 성과 창출에는 기여할 수 있겠지만, 장기적인 관점에서 인재 유지와 혁신적인 아이디어 발현에 어떤 영향을 미칠지는 미지수입니다. 특히 '996'을 긍정적인 사업 전망과 동일시하는 시각은 위험할 수 있습니다. 성과 창출을 위해서는 집중력과 창의성이 필수적이며, 이는 충분한 휴식과 균형 잡힌 삶을 통해서만 얻어질 수 있기 때문입니다. AI 기술 발전의 속도가 빠르다고 해서 인간의 능력과 지속 가능성을 간과해서는 안 됩니다. 건강한 기업 문화는 직원들의 행복과 성장을 바탕으로 할 때 비로소 지속 가능하며, 이는 결국 기업의 장기적인 성공으로 이어질 것입니다. '996' 문화가 일시적인 유행으로 끝나고, AI 시대에도 인간 중심의 가치가 존중되는 건강한 근무 환경이 조성되기를 기대합니다."
      }
    ],
    "hashTag": [
      "#AI스타트업",
      "#996근무",
      "#그라인드문화",
      "#실리콘밸리",
      "#미래기술",
      "#창업트렌드",
      "#초장시간근무"
    ]
  },
  {
    "date": "2025-10-22T18:00:00+09:00",
    "title": "딥시크, 텍스트를 이미지 데이터로 변환해 처리하는 획기적 LLM 출시",
    "article": "딥시크가 언어 모델의 근본적인 작동 방식을 뒤흔드는 새로운 모델을 발표했다. 겉보기에는 단순한 광학 문자 인식(OCR) 도구처럼 보이지만, 실제로는 언어 모델이 정보를 처리하는 패러다임 자체를 뒤집는 ‘시각 기반 정보 압축’ 기술이 핵심이다.\n딥시크는 21일(현지시간) 2차원 시각 매핑(Optical 2D Mapping)을 통한 장문 컨텍스트를 압축하는 새로운 OCR 모델 ‘딥시크-OCR(DeepSeek-OCR)’을 온라인 아카이브를 통해 공개했다.\n기존의 대형언어모델(LLM)은 텍스트를 토큰 단위로 쪼개 처리해 왔다.\n그러나, 딥시크-OCR은 이 구조를 완전히 변화시켰다. 텍스트를 이미지 형태로 변환해 처리하면, 정보량을 7~10배 적은 토큰으로 표현할 수 있다는 것이다.\n딥시크-OCR은 16배 압축 모듈을 통해 텍스트 데이터를 고해상도 시각 데이터로 변환한 뒤, 이를 다시 언어 형태로 해석하는 방식으로 작동한다.\n모델은 인코더 역할을 하는 '딥인코더(DeepEncoder)'와 디코더 역할을 하는 '딥시크3B-MoE-A570M'로 구성된다.\n약 3억8000만개의 매개변수를 가진 딥인코더는 메타의 SAM(Segment Anything Model)과 오픈AI의 CLIP을 결합한 것으로, 이를 통해 세부 정보와 전체 문맥을 동시에 이해하는 시각 인식 능력을 갖추고 있다.\n딥시크3B-MoE-A570M은 약 3억개의 활성 매개변수를 가진 전문가 혼합(MoE) 구조의 언어 디코더로, 이미지 입력으로부터 텍스트의 의미를 정밀하게 재구성하는 역할을 한다.\n연구진은 문서 인식 벤치마크 '폭스(Fox)' 데이터셋에서 모델을 검증했다.\n그 결과, 700~800개의 텍스트 토큰이 포함된 문서를 단 100개의 비전 토큰으로(압축비 약 7.5배) 처리하면서도 97.3%의 정확도를 기록했다. 압축비를 20배로 높일 경우에도 정확도를 60%로 유지했다.\n실용적인 성능 면에서도 주목할 만한 결과를 보였다.\n'옴니독벤치(OmniDocBench)' 벤치마크에서 딥시크-OCR은 페이지당 256개 토큰을 사용하는 'GOT-OCR2.0'을 단 100개의 비전 토큰만으로 능가했으며, 평균 페이지당 6000개 이상 토큰을 사용하는 'MinerU2.0'을 상대로는 800개 미만의 토큰으로 더 높은 성능을 보였다.\n이처럼 적은 토큰을 사용하는 것은 결과적으로 컨텍스트 창을 확장하는 효과를 낸다.\n딥시크는 이 모델로 단일 엔비디아 'A100' GPU에서 하루 20만 페이지 이상의 문서를 처리할 수 있으며, GPU 160개를 병렬로 운용하면 하루 3300만 페이지까지 처리할 수 있다고 밝혔다. 이는 대규모 AI 학습용 데이터셋을 압축·생성·관리하는 핵심 기술로 활용될 수 있다는 것을 보여준다.\n연구진은 이번 모델이 “텍스트를 시각적으로 표현함으로써 기존보다 최대 10배 높은 효율로 정보를 압축할 수 있다”라며 “이로 인해 언어 모델의 컨텍스트 창이 수천만 토큰 단위로 확장될 가능성이 열렸다”라고 강조했다.\n이에 대해 안드레이 카르파시 오픈AI 공동 창립자는 X(트위터)를 통해 “LLM에 대한 모든 입력은 이미지로만 하는 것이 더 합리적일지도 모른다”라며 “순수 텍스트 입력이라도, 렌더링 후 처리하는 것이 더 나을 수도 있다”라고 평했다.\n또 이번 연구가 “토크나이저(tokenizer)라는 구식 구조의 한계를 넘어서는 첫번째 현실적 대안”이라고 말했다. 그는 “토크나이저는 복잡하고 비효율적이며, 보안 취약성과 언어적 불일치를 초래한다”라며 “시각적 입력은 이런 문제를 자연스럽게 해결하면서, 서식·색상·레이아웃 등 문서의 구조적 정보까지 보존할 수 있다”라고 덧붙였다.\n딥시크-OCR 모델의 코드와 가중치는 허깅페이스와 깃허브에 공개됐다.\n박찬 기자 cpark@aitimes.com",
    "link": "https://www.aitimes.com/news/articleView.html?idxno=203348",
    "type": "AITIMES",
    "newTitle": "딥시크 OCR, 언어 모델 패러다임을 바꾸는 시각 기반 정보 압축 기술",
    "newArticle": [
      {
        "title": "딥시크 OCR 새 등장",
        "content": "딥시크에서 언어 모델의 작동 방식을 혁신할 새로운 모델을 선보였습니다. 겉보기에는 단순한 OCR 도구 같지만, 실제로는 언어 모델이 정보를 처리하는 방식 자체를 바꾸는 '시각 기반 정보 압축' 기술이 핵심입니다. 딥시크는 2차원 시각 매핑을 통해 장문의 텍스트 맥락을 압축하는 새로운 OCR 모델, 딥시크-OCR을 공개했습니다. 이 딥시크-OCR 기술은 기존 대형 언어 모델(LLM)이 텍스트를 토큰 단위로 쪼개 처리하던 방식에서 벗어나, 텍스트를 이미지 형태로 변환하여 정보를 처리합니다. 이를 통해 정보량을 7~10배 적은 토큰으로 표현하는 혁신을 이루었으며, 이는 딥시크-OCR의 가장 큰 특징입니다. 딥시크-OCR 모델은 16배 압축 모듈을 활용하여 텍스트 데이터를 고해상도 시각 데이터로 변환하고, 이를 다시 언어 형태로 해석하는 방식으로 작동하여 딥시크-OCR의 성능을 높였습니다. 딥시크-OCR은 이러한 혁신적인 기술로 AI 분야에 새로운 가능성을 제시하고 있습니다."
      },
      {
        "title": "새로운 OCR 작동 원리",
        "content": "딥시크-OCR 모델은 기존의 텍스트 토큰화 방식과는 근본적으로 다릅니다. 이 새로운 OCR 기술은 텍스트를 이미지 형태로 변환하여 처리함으로써, 정보량을 획기적으로 줄이는 데 성공했습니다. 딥시크-OCR은 16배 압축 모듈을 통해 텍스트 데이터를 고해상도 시각 데이터로 변환한 후, 이를 다시 언어 형태로 해석하는 과정을 거칩니다. 이 복잡한 과정은 딥인코더와 딥시크3B-MoE-A570M이라는 두 가지 핵심 구성 요소에 의해 수행됩니다. 딥인코더는 약 3억 8천만 개의 매개변수를 가진 인코더 역할을 하며, 메타의 SAM과 오픈AI의 CLIP을 결합하여 세부 정보와 전체 맥락을 동시에 이해하는 뛰어난 시각 인식 능력을 보여줍니다. 딥시크3B-MoE-A570M은 약 3억 개의 활성 매개변수를 가진 전문가 혼합(MoE) 구조의 언어 디코더로, 이미지 입력으로부터 텍스트의 의미를 정밀하게 재구성하는 역할을 담당합니다. 이러한 딥시크-OCR의 구조적 혁신은 기존 OCR 기술의 한계를 뛰어넘는 성능을 가능하게 합니다."
      },
      {
        "title": "벤치마크 성능 결과",
        "content": "딥시크-OCR 모델은 다양한 벤치마크 테스트를 통해 그 성능을 입증했습니다. 연구진은 문서 인식 벤치마크인 '폭스(Fox)' 데이터셋에서 딥시크-OCR 모델을 검증했습니다. 그 결과, 700~800개의 텍스트 토큰이 포함된 문서를 단 100개의 비전 토큰으로 처리하면서도 97.3%라는 높은 정확도를 기록했습니다. 이는 약 7.5배의 압축률에 해당하는 수치입니다. 심지어 압축비를 20배로 높였을 때도 60%의 정확도를 유지하는 놀라운 성능을 보여주었습니다. 실용적인 성능 측면에서도 딥시크-OCR은 주목할 만한 결과를 달성했습니다. '옴니독벤치(OmniDocBench)' 벤치마크에서 딥시크-OCR은 페이지당 256개의 토큰을 사용하는 'GOT-OCR2.0'을 단 100개의 비전 토큰만으로 능가하는 성과를 거두었습니다. 또한, 평균 페이지당 6000개 이상의 토큰을 사용하는 'MinerU2.0'을 상대로는 800개 미만의 토큰으로 더 높은 성능을 보여주며 딥시크-OCR의 효율성을 입증했습니다."
      },
      {
        "title": "컨텍스트 창 확장 효과",
        "content": "딥시크-OCR 모델이 적은 토큰을 사용하면서도 높은 성능을 유지하는 비결은 바로 '컨텍스트 창 확장' 효과에 있습니다. 기존의 텍스트 기반 언어 모델은 처리할 수 있는 토큰의 수가 제한되어 있어 긴 텍스트나 복잡한 문맥을 이해하는 데 한계가 있었습니다. 하지만 딥시크-OCR은 텍스트를 시각 정보로 압축하여 처리함으로써, 훨씬 더 많은 정보를 더 적은 양의 데이터로 담을 수 있게 되었습니다. 이는 결과적으로 언어 모델이 한 번에 처리할 수 있는 컨텍스트 창의 크기를 수천만 토큰 단위로 확장할 가능성을 열어줍니다. 딥시크는 이 모델을 통해 단일 엔비디아 'A100' GPU에서 하루 20만 페이지 이상의 문서를 처리할 수 있으며, GPU 160개를 병렬로 운용하면 하루 3300만 페이지까지 처리할 수 있다고 밝혔습니다. 이는 대규모 AI 학습용 데이터셋을 압축, 생성, 관리하는 데 핵심적인 기술로 활용될 수 있음을 시사하며, 딥시크-OCR의 잠재력을 보여줍니다."
      },
      {
        "title": "AI 전문가 반응",
        "content": "딥시크-OCR 모델의 혁신적인 결과에 대해 AI 전문가들의 긍정적인 반응이 잇따르고 있습니다. 오픈AI 공동 창립자인 안드레이 카르파시는 X(트위터)를 통해 \"LLM에 대한 모든 입력은 이미지로만 하는 것이 더 합리적일지도 모른다\"라며, \"순수 텍스트 입력이라도, 렌더링 후 처리하는 것이 더 나을 수도 있다\"고 언급했습니다. 이는 딥시크-OCR이 제시하는 시각 기반 정보 처리 방식의 가능성을 시사합니다. 또한, 그는 이번 연구가 \"토크나이저(tokenizer)라는 구식 구조의 한계를 넘어서는 첫 번째 현실적 대안\"이라고 평가하며, 기존 토크나이저의 비효율성, 보안 취약성, 언어적 불일치 문제를 지적했습니다. 반면, 시각적 입력은 이러한 문제들을 자연스럽게 해결하면서 서식, 색상, 레이아웃 등 문서의 구조적 정보까지 보존할 수 있다는 점에서 딥시크-OCR의 우수성을 강조했습니다. 이러한 전문가들의 의견은 딥시크-OCR이 AI 언어 모델의 미래에 중요한 변화를 가져올 수 있음을 보여줍니다."
      },
      {
        "title": "개인적인 생각",
        "content": "딥시크-OCR 모델의 등장은 AI 언어 모델 분야에 있어 매우 의미 있는 진전이라고 생각합니다. 기존의 토큰 기반 처리 방식이 가진 근본적인 한계를 시각 기반 압축이라는 새로운 패러다임으로 극복하려는 시도는 매우 혁신적입니다. 특히, 텍스트 정보를 이미지 형태로 변환하여 처리함으로써 정보량을 획기적으로 줄이고 컨텍스트 창을 확장할 수 있다는 점은 LLM의 성능 향상에 지대한 영향을 미칠 잠재력을 가지고 있습니다. 이는 곧 더 복잡하고 방대한 정보를 이해하고 처리할 수 있는 AI의 능력이 비약적으로 발전할 수 있음을 의미합니다. 안드레이 카르파시의 언급처럼, 텍스트를 시각적으로 처리하는 것이 앞으로 LLM의 표준이 될 가능성도 배제할 수 없습니다. 토크나이저의 한계를 넘어서는 딥시크-OCR은 보안, 효율성, 그리고 문서의 구조적 정보를 보존하는 측면에서도 명확한 이점을 가집니다. 이러한 기술 발전은 AI가 더욱 정교하고 자연스러운 방식으로 인간과 소통하고, 복잡한 문제를 해결하는 데 크게 기여할 것으로 기대됩니다. 딥시크-OCR 모델의 공개와 더불어 앞으로 이 기술이 어떻게 발전하고 실제 응용 분야에 적용될지 주목하는 것이 중요할 것입니다. 딥시크-OCR은 AI 언어 모델의 미래를 엿볼 수 있는 중요한 지표가 될 것입니다."
      }
    ],
    "hashTag": [
      "#딥시크OCR",
      "#언어모델",
      "#시각정보압축",
      "#AI기술",
      "#딥러닝",
      "#OCR",
      "#LLM",
      "#데이터압축",
      "#AI연구",
      "#혁신기술"
    ]
  },
  {
    "date": "2025-10-22T18:00:00+09:00",
    "title": "알리바바, ‘큐원 딥 리서치’ 업그레이드...리포트·웹페이지·팟캐스트까지 생성",
    "article": "알리바바가 클릭 몇번으로 연구 보고서부터 웹페이지, 팟캐스트까지 완성하는 통합형 인공지능(AI) 심층 연구 도구를 선보였다.\n알리바바는 21일(현지시간) AI 심층 연구 도구 ‘큐원 딥 리서치(Qwen Deep Research)’를 대폭 확장한 새로운 버전을 공개했다.\n이번 업데이트는 웹 챗봇 ‘큐원 챗(Qwen Chat)’에서 선택적으로 활성화할 수 있는 기능이다. 사용자는 단 1~2번의 클릭만으로 연구 보고서, 인터랙티브 웹페이지, 그리고 다중화자 팟캐스트까지 자동 생성할 수 있다.\n이번 업그레이드는 기존 오픈 소스 모델과 달리, 알리바바가 직접 관리·운영하는 독점형 서비스로 제공된다.\n핵심 기능은 '큐원3-코더(코드 생성)', '큐원-이미지(이미지 생성)', '큐원3-TTS(음성 합성)'에 의해 구동하지만, 데이터 수집·분석부터 웹 배포와 오디오 제작까지의 전 과정을 큐원이 통합 관리한다. 사용자는 별도의 서버 설정이나 인프라 구축 없이 완성된 형태의 AI 리서치 워크플로를 경험할 수 있다.\n큐원 챗에서 사용자가 주제를 입력하면 AI가 먼저 몇가지 질문으로 연구 범위를 파악한 뒤, 웹과 공식 자료에서 데이터를 수집하고 출처 간 불일치나 통계적 오류를 분석해 정리한다.\n결과가 생성되면 사용자는 결과창 아래의 ‘눈(eyeball)’ 아이콘을 눌러 오른쪽 패널에서 PDF 형태의 보고서를 즉시 확인할 수 있다.\n또 상단의 ‘생성(Create)’ 버튼을 통해 두가지 확장 형식 중 하나를 선택할 수 있다.\n웹 데브(Web Dev) 형식은 큐원3-코더와 큐원-이미지를 활용해 전문 수준의 웹페이지를 자동 생성하고 배포할 수 있다. 생성된 페이지에는 차트와 그래픽이 포함돼 프레젠테이션이나 교육 자료로 활용 가능하다.\n팟캐스트(Podcast) 형식은 큐원3-TTS를 통해 다중화자 음성을 생성해 대화형 오디오 팟캐스트를 제작할 수 있다. 최대 17명의 호스트와 7명의 공동 진행자 중 선택할 수 있으며, AI가 주제를 토론 형식으로 재구성한다.\n웹페이지는 공개 링크로 공유할 수 있지만, 팟캐스트는 파일 다운로드만 가능하며 외부 링크 공유 기능은 제공되지 않는다.\n큐원이 생성하는 팟캐스트는 단순한 리포트 음성 버전이 아니라, 두 명의 가상 진행자가 주제를 토론하며 심층 해설하는 포맷이다. ‘UFO 목격 사례’ 연구를 요청하면, 보고서에 없는 추가 이미지와 시각화를 포함한 웹페이지가 생성되고 동시에 두 진행자가 관련 역사적 맥락을 논의하는 팟캐스트가 제작된다. 현재 인터페이스에서 음성 미리듣기나 언어 변경 기능은 제공되지 않으며, 기본 출력은 영어다.\n큐원 딥 리서치는 큐원 챗 앱에서 바로 이용 가능하며, 접속 링크를 통해 접근할 수 있다.\n알리바바는 이번 업데이트에 대한 가격 정책이나 구독 플랜은 아직 공개하지 않았다.\n박찬 기자 cpark@aitimes.com",
    "link": "https://www.aitimes.com/news/articleView.html?idxno=203350",
    "type": "AITIMES",
    "newTitle": "알리바바 AI, 클릭 몇 번으로 리포트 웹페이지 팟캐스트까지 뚝딱",
    "newArticle": [
      {
        "title": "알리바바 AI 리서치 도구",
        "content": "알리바바가 인공지능(AI) 기반의 혁신적인 심층 연구 도구인 '큐원 딥 리서치(Qwen Deep Research)'의 새로운 버전을 공개하며 AI 연구 및 콘텐츠 생성 분야에 새로운 지평을 열었습니다. 이번 업데이트는 사용자가 단 몇 번의 클릭만으로 복잡한 연구 보고서, 인터랙티브 웹페이지, 그리고 다중화자 팟캐스트까지 자동 생성할 수 있도록 기능을 대폭 확장한 것이 특징입니다. 기존의 오픈 소스 모델과 달리, 알리바바가 직접 관리하고 운영하는 독점형 서비스로 제공되어 더욱 안정적이고 통합적인 AI 리서치 워크플로를 경험할 수 있습니다. 사용자는 별도의 서버 설정이나 복잡한 인프라 구축 없이도 강력한 AI 기반 연구 도구를 손쉽게 활용할 수 있게 되었습니다. 알리바바의 이번 AI 리서치 도구 출시는 콘텐츠 제작 및 정보 분석 방식에 상당한 변화를 가져올 것으로 기대됩니다."
      },
      {
        "title": "AI 리서치 워크플로",
        "content": "알리바바의 새로운 AI 심층 연구 도구는 사용자의 편의성을 극대화한 통합형 워크플로를 제공합니다. 사용자가 '큐원 챗'에서 원하는 주제를 입력하면, AI는 먼저 질문을 통해 연구 범위를 명확히 파악한 후, 웹과 공식 자료에서 방대한 데이터를 수집하고 분석합니다. 이 과정에서 AI는 출처 간의 불일치나 통계적 오류를 꼼꼼하게 검토하고 정리하여 신뢰도 높은 정보를 제공합니다. 최종 결과물은 PDF 형태의 보고서로 즉시 확인 가능하며, '눈(eyeball)' 아이콘을 통해 간편하게 접근할 수 있습니다. 이러한 AI 리서치 워크플로는 정보 수집, 분석, 보고서 작성에 소요되는 시간과 노력을 획기적으로 단축시켜주며, 사용자는 더욱 효율적으로 연구를 수행할 수 있게 됩니다."
      },
      {
        "title": "AI 웹페이지 생성",
        "content": "알리바바의 AI 심층 연구 도구는 '큐원3-코더'와 '큐원-이미지'를 활용하여 전문적인 수준의 웹페이지를 자동으로 생성하고 배포하는 강력한 기능을 제공합니다. '생성(Create)' 버튼에서 'Web Dev' 형식을 선택하면, AI는 입력된 연구 주제에 맞춰 시각적으로 매력적이고 정보 전달력이 높은 웹페이지를 만들어냅니다. 이 웹페이지에는 차트와 그래픽이 포함될 수 있어, 프레젠테이션 자료나 교육 콘텐츠로 활용하기에 매우 적합합니다. 사용자는 별도의 코딩 지식 없이도 맞춤형 웹사이트를 제작할 수 있으며, 생성된 웹페이지는 공개 링크를 통해 쉽게 공유할 수 있습니다. 이는 개인 블로그, 비즈니스 소개 페이지, 또는 교육용 자료 제작 등 다양한 분야에서 혁신적인 활용 가능성을 제시합니다."
      },
      {
        "title": "AI 팟캐스트 제작",
        "content": "알리바바의 AI 심층 연구 도구는 '큐원3-TTS'를 이용해 마치 실제 사람처럼 자연스러운 대화형 오디오 팟캐스트를 제작하는 기능까지 포함하고 있습니다. '생성(Create)' 버튼에서 'Podcast' 형식을 선택하면, AI는 입력된 연구 주제를 토론 형식으로 재구성하고, 최대 17명의 호스트와 7명의 공동 진행자 중에서 선택하여 다중화자 음성을 생성합니다. 이는 단순한 텍스트를 음성으로 읽어주는 것을 넘어, 두 명의 가상 진행자가 주제에 대해 심도 있는 토론을 펼치며 청취자에게 풍부한 정보와 해설을 제공하는 포맷입니다. 예를 들어 'UFO 목격 사례' 연구 요청 시, 보고서와 웹페이지 생성과 함께 관련 역사적 맥락을 논의하는 팟캐스트가 자동으로 제작됩니다. 현재는 영어로만 제공되며, 음성 미리듣기나 언어 변경 기능은 추후 제공될 것으로 예상됩니다. 생성된 팟캐스트는 파일 다운로드만 가능합니다."
      },
      {
        "title": "AI 콘텐츠 생성 통합",
        "content": "이번 알리바바의 AI 심층 연구 도구의 핵심은 다양한 콘텐츠 생성 기능을 하나의 플랫폼으로 통합했다는 점입니다. '큐원 딥 리서치'는 연구 보고서 작성, 웹페이지 구축, 팟캐스트 제작에 이르기까지 AI의 핵심 역량인 '큐원3-코더', '큐원-이미지', '큐원3-TTS'를 유기적으로 결합하여 활용합니다. 사용자는 단일 인터페이스 안에서 데이터 수집부터 분석, 보고서 생성, 시각 자료 포함 웹페이지 제작, 그리고 대화형 오디오 콘텐츠 제작까지 전 과정을 경험할 수 있습니다. 이는 AI 기술의 복잡한 활용을 단순화하고, 사용자가 콘텐츠 크리에이터로서의 역할을 더욱 쉽고 효과적으로 수행할 수 있도록 지원합니다. 이러한 통합형 AI 리서치 도구의 등장은 개인 및 기업의 콘텐츠 제작 방식에 패러다임 전환을 가져올 것으로 전망됩니다."
      },
      {
        "title": "개인적인 생각",
        "content": "알리바바의 '큐원 딥 리서치'는 AI 기술이 연구 및 콘텐츠 제작 분야에 미칠 파급력을 여실히 보여주는 사례라고 생각합니다. 몇 번의 클릭만으로 보고서, 웹페이지, 팟캐스트까지 자동으로 생성하는 능력은 정보 접근성과 생산성을 획기적으로 높일 잠재력을 가지고 있습니다. 특히, 복잡한 인프라 구축 없이도 전문가 수준의 결과물을 얻을 수 있다는 점은 개인 연구자나 소규모 팀에게 큰 이점을 제공할 것입니다. 하지만 AI가 생성하는 정보의 정확성, 독창성, 그리고 윤리적인 문제에 대한 심층적인 검토와 사회적 합의가 필요합니다. 또한, AI 생성 콘텐츠의 저작권 문제, 인간의 창의성과 AI의 역할을 어떻게 조화시킬 것인가에 대한 논의도 중요합니다. 알리바바의 이러한 행보는 AI가 단순한 도구를 넘어, 우리의 사고방식과 일하는 방식을 근본적으로 변화시킬 것임을 시사합니다. 앞으로 AI 기술의 발전과 함께 이러한 도구들이 어떻게 진화하고 우리 삶에 통합될지 주의 깊게 지켜봐야 할 것입니다. AI 리서치 도구의 가격 정책 및 구독 플랜 공개 여부도 향후 활용도에 중요한 변수가 될 것입니다."
      }
    ],
    "hashTag": [
      "#알리바바AI",
      "#큐원딥리서치",
      "#AI연구도구",
      "#자동보고서생성",
      "#AI팟캐스트",
      "#AI웹페이지생성",
      "#QwenDeepResearch",
      "#인공지능신기술"
    ]
  },
  {
    "date": "2025-10-22T18:00:00+09:00",
    "title": "쉴드 AI, 수직이착륙 가능한 최초의 AI 군용 드론 공개",
    "article": "미국의 국방 인공지능(AI) 쉴드 AI가 첨단 군사용 무인 항공기를 선보였다.\n쉴드 AI는 22일 차세대 무인 전투기 'X-배트(X-Bat)'를 영상을 공개했다.  제트 엔진을 장착했으며, 최대 15km 고도로 3200km를 비행할 수 있다. 또 길이 3.8m, 날개폭과 높이 2.9m, 중량 73kg으로, 이전 'V-배트' 모델보다 더 커졌다.\n이 고정익 드론은 수직 이착륙이 가능하다는 것이 장점이다.  활주로가 없는 외딴 지역이나 바다 한가운데의 배에서도 운항할 수 있다. 또 이전 버전과 달리 전투를 위해 설계됐으며, 미사일을 장착할 수도 있다.\n여기에는 쉴드 AI가 개발한 '하이브마인드(Hivemind)'라는 AI가 적용된다. 이는 미국 국방성 산하 방위고등연구계획국(DARPA)의 AC 프로젝트에 참여, F-16 전투기의 자율비행과 공중전 기동을 성공적으로 수행한 바 있다.\n브랜든 청 쉴드 AI 사장 겸 공동 창립자는 ”AI 조종과 수직 이착륙이라는 두가지 요소가 차세대 항공기 형태로 결합한 적은 없다”라고 밝혔다. 게리 스틸 CEO도 ”AI는 우리가 하는 모든 일의 초석이자 기반”이라며 ”이 소프트웨어는 차세대 항공기 개발을 가능하게 하므로 궁극적으로 이 사업의 장기적인 성장 동력이 될 것”이라고 말했다.\n이 회사는 X-배트를 약 2700만달러(약 386억원)에 생산할 계획이라고 밝혔다. 이는 현재 1억달러(약 1439억원)가 넘는 F-35 전투기 제작비의 일부에 불과하다.\n한편, 쉴드 AI는 최근 투자 라운드에서 기업 가치 53억달러(약 7조5785억원)에 2억4000만달러를 유치한 바 있다. 2015년부터 사업을 시작, 이미 여러 주요 방위 계약을 체결했다. 2024년에는 미국 해안경비대와 2억달러 규모의 무인 항공기 공급 계약을 체결했다.\n임대준 기자 ydj@aitimes.com",
    "link": "https://www.aitimes.com/news/articleView.html?idxno=203351",
    "type": "AITIMES",
    "newTitle": "쉴드 AI, AI 자율 비행 군용 드론 X-배트 공개",
    "newArticle": [
      {
        "title": "AI 무인기 'X-배트' 공개",
        "content": "미국의 국방 인공지능(AI) 전문 기업 쉴드 AI가 혁신적인 차세대 군사용 무인 항공기 'X-배트'를 선보이며 이목을 집중시키고 있습니다. 쉴드 AI는 최근 공개한 영상을 통해 제트 엔진을 장착한 X-배트의 성능을 과시했습니다. 이 첨단 무인기는 최대 15km 고도까지 상승하여 3200km에 달하는 장거리를 비행할 수 있는 능력을 갖추고 있습니다. 길이 3.8m, 날개폭과 높이 2.9m, 중량 73kg의 X-배트는 이전 모델인 'V-배트'보다 더욱 커진 크기를 자랑하며, 이는 더 많은 탑재량과 향상된 성능을 기대하게 합니다. 이러한 X-배트의 등장은 군사 기술의 새로운 지평을 열 것으로 예상되며, AI 무인기의 미래를 엿볼 수 있는 중요한 사건입니다."
      },
      {
        "title": "수직 이착륙의 혁신",
        "content": "X-배트의 가장 큰 특징 중 하나는 뛰어난 수직 이착륙(VTOL) 능력입니다. 이 고정익 드론은 별도의 활주로가 없는 험준한 산악 지형이나 광활한 바다 한가운데 떠 있는 함선 위에서도 자유롭게 이착륙할 수 있습니다. 이러한 유연성은 기존 항공기의 운용 제약을 획기적으로 극복하는 것으로, 다양한 작전 환경에서 신속하고 효과적인 임무 수행을 가능하게 합니다. 기존의 무인 항공기들이 주로 이착륙을 위한 특정 시설을 필요로 했던 것과 달리, X-배트는 이러한 제약을 벗어나 작전 반경을 대폭 확장할 수 있다는 점에서 큰 강점을 지닙니다. 이는 전술적 운용의 효율성을 극대화하는 중요한 요소입니다."
      },
      {
        "title": "강력한 전투 능력 장착",
        "content": "이전 모델과 달리 X-배트는 순수한 전투 임무 수행을 위해 특별히 설계되었습니다. 단순히 정찰이나 감시 임무를 넘어, X-배트는 미사일과 같은 다양한 무기 체계를 장착할 수 있도록 개발되었습니다. 이는 AI 무인기가 단순한 보조 역할을 넘어 주력 전투 플랫폼으로 진화할 수 있는 가능성을 보여줍니다. 쉴드 AI의 기술력은 이러한 X-배트에 적용된 '하이브마인드(Hivemind)'라는 AI 시스템에서 빛을 발합니다. 이 AI는 미국 국방성 산하 방위고등연구계획국(DARPA)의 AC 프로젝트에 참여하여 F-16 전투기의 자율비행과 공중전 기동을 성공적으로 수행한 경험을 가지고 있습니다. 하이브마인드는 X-배트가 복잡한 전장 환경에서 스스로 판단하고 작전을 수행하는 핵심 두뇌 역할을 하게 됩니다."
      },
      {
        "title": "AI 조종과 VTOL 결합",
        "content": "브랜든 청 쉴드 AI 사장 겸 공동 창립자는 AI 조종과 수직 이착륙이라는 두 가지 혁신적인 기술이 차세대 항공기 형태로 결합된 것은 처음이라고 강조했습니다. 이러한 기술 융합은 X-배트를 더욱 독보적인 존재로 만듭니다. 게리 스틸 CEO 역시 AI가 회사의 모든 활동의 근간이며, AI 소프트웨어가 차세대 항공기 개발을 가능하게 하는 핵심 동력이라고 언급했습니다. 이러한 AI 기반의 접근 방식은 쉴드 AI가 미래 항공 기술을 선도하고 지속적인 성장을 이룰 수 있는 강력한 기반이 될 것입니다. AI 기술의 발전은 무인 항공기의 성능과 운용 방식을 근본적으로 변화시키고 있습니다."
      },
      {
        "title": "경제적인 가격 경쟁력",
        "content": "X-배트의 또 다른 매력적인 부분은 뛰어난 가격 경쟁력입니다. 쉴드 AI는 X-배트를 약 2700만 달러(약 386억원)에 생산할 계획이라고 밝혔습니다. 이는 현재 1억 달러(약 1439억원)가 넘는 F-35 전투기와 비교했을 때 훨씬 저렴한 가격입니다. 비록 F-35와 직접적인 성능 비교는 어렵지만, X-배트가 제공하는 첨단 AI 기술과 수직 이착륙 능력, 그리고 전투 기능 등을 고려할 때 매우 합리적인 가격이라고 볼 수 있습니다. 이러한 경제성은 군에 도입될 AI 무인기 시장에서 쉴드 AI의 입지를 더욱 공고히 할 것으로 예상됩니다. 가격 경쟁력은 첨단 기술 도입의 장벽을 낮추는 중요한 요소입니다."
      },
      {
        "title": "가파른 성장세와 사업 확장",
        "content": "쉴드 AI는 최근 투자 유치에서 기업 가치 53억 달러(약 7조 5785억원)에 2억 4000만 달러를 성공적으로 조달하며 가파른 성장세를 입증했습니다. 2015년부터 사업을 시작한 이래, 쉴드 AI는 이미 여러 주요 방위 계약을 체결하는 등 실질적인 성과를 거두고 있습니다. 특히 2024년에는 미국 해안경비대와 2억 달러 규모의 무인 항공기 공급 계약을 체결하며 사업 영역을 확장하고 있습니다. 이는 쉴드 AI의 기술력과 미래 성장 가능성을 시장이 높게 평가하고 있음을 보여주는 명확한 증거입니다. AI 무인기 시장은 앞으로 더욱 확대될 것으로 예상되며, 쉴드 AI는 이 시장을 선도할 강력한 후보로 떠오르고 있습니다."
      },
      {
        "title": "개인적인 생각",
        "content": "쉴드 AI의 X-배트 공개는 AI 무인기 기술이 단순한 개념을 넘어 실질적인 군사적 위협과 가치를 지니는 단계로 진입했음을 보여줍니다. AI 조종과 수직 이착륙 기능의 결합은 작전의 유연성을 극대화하며, 전투 기능 탑재는 AI 무인기의 역할 확대를 시사합니다. 특히 F-35와 비교되는 경제적인 가격은 향후 군의 무기 체계 도입에 있어 AI 무인기가 매력적인 대안으로 떠오를 수 있음을 암시합니다. 다만, AI의 의사결정 과정의 투명성과 신뢰성 확보, 그리고 예상치 못한 오작동 가능성에 대한 철저한 검증이 동반되어야 할 것입니다. AI 무인기 시대의 도래는 국제 안보 지형에 큰 변화를 가져올 것이며, 이에 대한 지속적인 관심과 분석이 필요하다고 생각합니다."
      }
    ],
    "hashTag": [
      "#방산AI",
      "#무인전투기",
      "#X배트",
      "#쉴드AI",
      "#AI드론",
      "#자율비행",
      "#미사일탑재",
      "#차세대무기",
      "#첨단항공기",
      "#미국국방"
    ]
  },
  {
    "date": "2025-10-22T18:00:00+09:00",
    "title": "밀라 연구소, 추론을 3배 효율적으로 수행하는 학습법 ‘마르코프 사고’ 공개",
    "article": "대형언어모델(LLM)의 ‘사고 방식’을 근본적으로 재설계하려는 시도가 등장했다. 캐나다 AI 연구소 밀라(Mila) 연구진이 제안한 새로운 학습 기법은, 모델이 스스로 생각을 구획화하고 이어가는 방식을 통해 연산 효율을 비약적으로 높이는 데 초점을 맞췄다.\n밀라 연구소는 21일(현지시간) LLM의 복잡한 추론 효율을 획기적으로 개선할 수 있는 새로운 학습 방식 ‘마르코프 싱커(Markovian Thinker)’를 온라인 아카이브를 통해 공개했다.\n이 방법은 AI가 긴 추론 과정을 수행할 때 발생하는 연산 비용 폭증 문제를 근본적으로 해결해, 기존 방식에 비해 훈련 비용을 3분의 1 이하로 줄일 수 있다는 점에서 주목받고 있다.\nLLM이 복잡한 문제를 풀기 위해서는 단계별로 사고 과정을 나열하는 사고 사슬(CoT)이 필수적이다. 최근에는 강화 학습(RL)을 이용해 AI가 더 긴 사고를 하도록 훈련하는 롱CoT(LongCoT) 방식이 도입됐으나, 이 방식은 추론이 길어질수록 모델의 입력 상태(프롬프트 + 사고 토큰)가 기하급수적으로 커지며, 계산량이 토큰 길이에 따라 제곱으로 증가(Quadratic scaling)하는 문제가 있었다.\n밀라 연구진은 '사고 환경(thinking environment)' 자체를 재설계함으로써 이런 한계를 해결했다. 연구진은 “사고의 길이와 컨텍스트의 크기를 분리하는 것”이 핵심이라고 설명했다.\n연구진이 제안한 ‘딜리싱크(Delethink)’ 환경은 모델이 사고를 고정 크기(8000토큰)의 블록 단위로 수행하도록 설계됐다. 각 블록 안에서는 일반적인 추론을 수행하며, 블록이 끝나면 환경이 초기화되며 이전 단계의 핵심 내용을 요약한 ‘마르코프 상태(Markovian state)’만 다음 블록으로 전달된다.\n이 과정에서 모델은 스스로 다음 사고를 이어가기 위해 무엇을 기억해야 하는지 학습하게 된다. 연구진은 “모델이 훈련을 통해 중요한 상태 정보를 자동으로 요약하고 전달하도록 학습한다”라며 “이 방식은 입력 데이터나 프롬프트를 변경하지 않고 순수하게 추론 단계에서 작동한다”라고 설명했다.\n연구진은 딥시크의 'R1-Distill-1.5B'을 딜리싱크 환경에서 학습해 수학 경진대회 수준의 문제를 대상으로 벤치마크를 실시했다. 그 결과, 모델은 8000 토큰 단위로 사고하면서도 최대 2만4000 토큰까지 추론을 확장할 수 있었으며, 동일한 학습 예산을 사용한 롱CoT 모델과 비교해 동등하거나 그 이상의 정확도를 기록했다.\n특히 학습 한계를 넘어선 테스트에서도 지속적인 성능 향상을 보였다. 롱CoT 모델은 2만4000 토큰 이후 성능이 정체됐지만, 딜리싱크 모델은 14만 토큰까지 사고를 확장하며 정확도를 높였다.\n연구진은 “평균 사고 길이 9만6000 토큰 수준의 모델을 훈련할 경우, 롱CoT 방식은 'H100' GPU 27개월분의 연산이 필요하지만, 딜리싱크는 7개월분만으로 동일한 학습을 수행할 수 있다”라고 밝혔다.\n또, 별도의 훈련 없이도 일부 대형 모델(GPT-OSS 120B)이 이미 부분적으로 마르코프적 사고를 수행할 수 있음을 발견했다. 이는 딜리싱크와 같은 구조적 접근이 기존 모델에도 즉시 적용 가능다는 것을 의미한다.\n연구진은 마르코프 싱커의 모델과 코드를 허깅페이스와 깃허브에 공개했다.\n박찬 기자 cpark@aitimes.com",
    "link": "https://www.aitimes.com/news/articleView.html?idxno=203354",
    "type": "AITIMES",
    "newTitle": "LLM 추론 효율 3배 높이는 밀라 연구소의 새로운 학습법",
    "newArticle": [
      {
        "title": "LLM 사고 재설계",
        "content": "인공지능 분야에서 대형언어모델(LLM)의 근본적인 사고 방식을 혁신하려는 시도가 등장했습니다. 캐나다 AI 연구소 밀라(Mila)의 연구진은 모델이 스스로 생각을 구획화하고 순차적으로 이어가는 새로운 학습 기법을 제안하며, 이를 통해 연산 효율을 비약적으로 향상시키는 데 초점을 맞추었습니다. 기존 LLM은 복잡한 추론 과정에서 발생하는 연산 비용 폭증 문제가 있었는데, 이번 연구는 이러한 한계를 극복하고 훈련 비용을 획기적으로 절감할 수 있는 가능성을 제시합니다. 특히, AI의 연산 효율성을 높이기 위한 새로운 학습 방식의 등장은 앞으로 LLM 기술 발전의 중요한 전환점이 될 것으로 기대됩니다. 이 혁신적인 접근 방식은 AI가 더욱 복잡하고 긴 추론을 효율적으로 수행하도록 만드는 데 기여할 것입니다. LLM의 사고 구조를 재설계하는 이번 연구는 AI의 성능과 활용성을 한 단계 끌어올릴 잠재력을 가지고 있습니다."
      },
      {
        "title": "마르코프 싱커 공개",
        "content": "밀라 연구소는 최근 LLM의 복잡한 추론 효율을 획기적으로 개선할 수 있는 새로운 학습 방식인 ‘마르코프 싱커(Markovian Thinker)’를 온라인 아카이브를 통해 공개했습니다. 이 방법은 AI가 긴 추론 과정을 수행할 때 발생하는 치명적인 연산 비용 폭증 문제를 근본적으로 해결함으로써, 기존 방식에 비해 훈련 비용을 3분의 1 이하로 줄일 수 있다는 점에서 큰 주목을 받고 있습니다. 마르코프 싱커는 LLM이 마치 사람처럼 단계별로 생각을 정리하고 다음 단계로 연결하는 과정을 학습하도록 설계되었습니다. 이러한 접근 방식은 AI가 보다 복잡하고 심층적인 문제 해결 능력을 갖추도록 돕고, 동시에 컴퓨팅 자원 소모를 최소화하는 데 기여할 것입니다. 마르코프 싱커라는 새로운 학습 방식의 등장은 AI 연산 효율성 문제를 해결하는 데 중요한 진전을 가져올 것으로 보입니다."
      },
      {
        "title": "기존 CoT 한계 극복",
        "content": "LLM이 복잡한 문제를 효과적으로 해결하기 위해서는 단계별 사고 과정을 명확하게 나열하는 사고 사슬(CoT) 방식이 필수적입니다. 최근에는 강화 학습(RL)을 활용하여 AI가 더 긴 사고 과정을 수행하도록 훈련하는 롱CoT(LongCoT) 방식이 도입되었지만, 추론이 길어질수록 모델의 입력 상태(프롬프트 + 사고 토큰)가 기하급수적으로 커지면서 계산량이 토큰 길이에 따라 제곱으로 증가하는(Quadratic scaling) 문제가 발생했습니다. 이는 LLM의 실질적인 활용 범위를 제약하는 주요 요인으로 작용해 왔습니다. 밀라 연구진이 제안한 마르코프 싱커는 이러한 롱CoT의 근본적인 한계를 극복하고, 보다 효율적인 추론 방식을 제공하여 LLM의 성능을 한 단계 끌어올릴 것으로 기대됩니다. 롱CoT의 계산량 문제를 해결하는 것은 LLM의 실용성을 크게 높이는 중요한 과제입니다."
      },
      {
        "title": "딜리싱크 환경 설계",
        "content": "밀라 연구진은 ‘사고 환경(thinking environment)’ 자체를 재설계하여 기존 LLM의 한계를 돌파했습니다. 핵심 아이디어는 '사고의 길이와 컨텍스트의 크기를 분리하는 것'입니다. 연구진이 제안한 ‘딜리싱크(Delethink)’ 환경은 모델이 사고 과정을 고정된 크기(8000 토큰)의 블록 단위로 수행하도록 설계되었습니다. 각 블록 내에서는 일반적인 추론 과정을 진행하며, 블록이 완료되면 환경이 초기화되고 이전 단계의 핵심 내용을 요약한 ‘마르코프 상태(Markovian state)’만이 다음 블록으로 전달됩니다. 이 과정을 통해 모델은 스스로 다음 사고를 이어가기 위해 어떤 정보를 기억해야 하는지를 학습하게 됩니다. 딜리싱크 환경은 LLM의 추론 과정을 보다 체계적이고 효율적으로 관리하여 연산 부담을 줄이는 데 중점을 둡니다. 이러한 혁신적인 환경 설계는 LLM이 더 길고 복잡한 문제에 대해 일관된 성능을 유지하도록 돕습니다."
      },
      {
        "title": "학습 효율성 입증",
        "content": "밀라 연구진은 딥시크의 'R1-Distill-1.5B' 모델을 딜리싱크 환경에서 학습시키고, 수학 경진대회 수준의 복잡한 문제들을 대상으로 벤치마크를 실시했습니다. 그 결과, 8000 토큰 단위로 사고를 분할하면서도 최대 2만4000 토큰까지 추론을 효과적으로 확장할 수 있었으며, 동일한 학습 예산을 사용한 롱CoT 모델과 비교했을 때 동등하거나 그 이상의 정확도를 기록했습니다. 특히 주목할 점은 학습 한계를 넘어선 테스트에서도 지속적인 성능 향상을 보였다는 것입니다. 롱CoT 모델의 경우 2만4000 토큰 이후 성능이 정체되는 반면, 딜리싱크 모델은 14만 토큰까지 사고를 확장하며 정확도를 꾸준히 높여갔습니다. 이는 딜리싱크 방식이 LLM의 추론 길이를 비약적으로 늘리면서도 성능 저하 없이 효율성을 유지할 수 있음을 명확히 보여주는 결과입니다. 학습 효율성 측면에서의 이러한 입증은 LLM의 실질적인 활용도를 높이는 데 크게 기여할 것입니다."
      },
      {
        "title": "비용 절감 효과",
        "content": "마르코프 싱커의 실제적인 비용 절감 효과는 매우 큽니다. 연구진은 평균 사고 길이 9만6000 토큰 수준의 모델을 훈련할 경우, 롱CoT 방식으로는 'H100' GPU 27개월분의 연산 자원이 필요하지만, 딜리싱크 방식으로는 단 7개월분의 연산으로 동일한 학습을 수행할 수 있다고 밝혔습니다. 이는 연산 시간과 비용 면에서 압도적인 효율성을 의미하며, LLM 연구 및 개발에 소요되는 막대한 비용 부담을 획기적으로 줄일 수 있습니다. 또한, 별도의 훈련 과정 없이도 일부 대형 모델(GPT-OSS 120B)이 이미 부분적으로 마르코프적 사고를 수행할 수 있음을 발견했는데, 이는 딜리싱크와 같은 구조적 접근이 기존 모델에도 즉시 적용 가능함을 시사합니다. 이러한 비용 절감 효과는 LLM 기술의 대중화와 더 많은 분야에서의 활용을 촉진할 것입니다. LLM의 훈련 및 운영 비용 절감은 AI 기술 발전의 속도를 가속화하는 중요한 요인입니다."
      },
      {
        "title": "개인적인 생각",
        "content": "밀라 연구소의 ‘마르코프 싱커’와 ‘딜리싱크’는 LLM의 연산 효율성 문제를 해결하는 데 있어 매우 혁신적인 접근 방식이라고 생각합니다. 기존 롱CoT의 제곱 증가 문제는 LLM의 발전 속도를 제약하는 주요 병목 현상이었는데, 이를 사고 길이와 컨텍스트 크기를 분리하는 아이디어로 돌파한 것은 LLM의 확장성과 실질적인 활용 가능성을 크게 높일 것으로 보입니다. 특히, GPU 연산 시간과 비용을 획기적으로 절감할 수 있다는 점은 LLM 기술의 대중화와 연구 개발에 드는 진입 장벽을 낮추는 데 크게 기여할 것입니다. 또한, 기존 모델에도 즉시 적용 가능하다는 점은 현재 LLM 생태계에 미치는 파급력이 상당할 것으로 예상됩니다. 앞으로 이러한 효율적인 학습 방식이 더욱 발전하고 다양한 LLM 모델에 적용된다면, AI는 더욱 복잡하고 창의적인 문제 해결에 기여할 수 있을 것입니다. LLM이 인간의 사고 과정을 더 깊이 이해하고 모방하려는 시도는 AI의 미래에 대한 흥미로운 가능성을 열어주고 있습니다."
      }
    ],
    "hashTag": [
      "#LLM",
      "#인공지능",
      "#AI연구",
      "#밀라AI",
      "#마르코프싱커"
    ]
  },
  {
    "date": "2025-10-22T17:27:00+09:00",
    "title": "마키나락스, 해군 함정 특화 ‘장비 운용 AI 참모’ 개발 착수",
    "article": "산업 특화 인공지능(AI) 전문 마키나락스(대표 윤성호)는 해군 1함대사령부와 함정의 장비 운용 및 관리를 지원하는 ‘장비운용 AI참모’ 개발에 나선다고 22일 밝혔다.\n이번 과제는 ‘방산혁신기업100’ 선정기술인 ‘국방 통합 인공지능 플랫폼’을 기반으로 하며, 개발 기간은 이달부터 내년 10월까지로 1년이다.\n장비 운용교범과 정비지침서 등 방대한 자료를 AI가 학습하고, 일일 단위로 쌓이는 운용 및 정비 결과를 실시간 반영해 승조원이 손쉽게 장비를 운용-관리할 수 있도록 돕는 것이 목표다. 해군 함정은 네트워크와 GPU 자원이 제한된 환경으로, 기존 클라우드 기반 AI 시스템 적용에는 한계를 갖고 있다는 설명이다.\n이에 마키나락스는 자체 AI 플랫폼 ‘런웨이’를 기반으로 k3s 기반 경량 LLM옵스 환경을 구축하고, 온보드 데이터 전처리 기술을 적용하며 특수한 군사 환경의 제약을 극복할 예정이다. 복잡한 운용교범과 정비지침서는 벡터 데이터베이스에 저장되고, 리트리벌 에이전트(Retrieval Agent)와 대형언어모델(LLM) 기반 응답 시스템을 통해 현장에서 즉시 활용할 수 있는 지능형 지원 체계를 구현할 계획이다.\n특히, Mk.45 5인치 함포와 같은 핵심 무장 체계 운용을 지원, 저숙련 인원도 무기를 효율적으로 다룰 수 있는 기반을 마련한다는 설명이다.\n윤성호 마키나락스 대표는 “이번 과제는 네트워크와 자원이 제한된 실제 함정 환경에서 AI 운용 가능성을 검증한다는 점에서 의미가 크다”라며 “복잡한 운용교범과 정비지침서를 AI가 실시간으로 학습 및 제공해 현장의 장비운용 및 관리 능력을 향상하는 실질적인 사례를 만들어 AI의 효용감을 직접 체감할 수 있도록 하겠다”라고 말했다.\n한편, 마키나락스는 ‘방산혁신기업 100’에 선정된 62개 기업 중 유일하게 자체 AI 플랫폼을 보유하고 있는 기업이라고 밝혔다.\n장세민 기자 semim99@aitimes.com",
    "link": "https://www.aitimes.com/news/articleView.html?idxno=203362",
    "type": "AITIMES",
    "newTitle": "마키나락스, 해군 함정 운용 돕는 AI 참모 개발 시작",
    "newArticle": [
      {
        "title": "AI, 해군 함정 운용 돕는다",
        "content": "산업 특화 인공지능(AI) 전문 기업 마키나락스가 해군 1함대사령부와 협력하여 함정의 장비 운용 및 관리를 획기적으로 지원하는 ‘장비운용 AI참모’ 개발에 착수했습니다. 이번 프로젝트는 이미 ‘방산혁신기업100’으로 선정된 마키나락스의 핵심 기술인 ‘국방 통합 인공지능 플랫폼’을 기반으로 진행되며, 약 1년간의 개발 기간을 거쳐 올해 10월까지 완료될 예정입니다. 이 AI참모는 방대한 장비 운용 교범과 정비 지침서를 AI가 학습하고, 일일 단위로 누적되는 실제 운용 및 정비 데이터를 실시간으로 반영하여 승조원들이 함정 장비를 더욱 쉽고 효율적으로 운용하고 관리할 수 있도록 돕는 것을 목표로 합니다. 특히, 해군 함정 환경은 네트워크 및 GPU 자원이 제한적인 특수 환경임을 고려하여, 기존 클라우드 기반 AI 시스템의 한계를 극복하는 데 중점을 둘 것입니다. 이러한 AI 기술의 해군 적용은 장비 관리의 효율성을 높이고, 궁극적으로는 해군 전력 강화에 기여할 것으로 기대됩니다."
      },
      {
        "title": "마키나락스 AI 플랫폼의 힘",
        "content": "마키나락스는 이번 해군 함정용 AI참모 개발에 있어 자체 AI 플랫폼 ‘런웨이’를 핵심 기술로 활용합니다. 네트워크와 GPU 자원이 제한적인 함정 내부 환경의 제약을 극복하기 위해, k3s 기반의 경량 LLM옵스(LLMOps) 환경을 구축하고 온보드 데이터 전처리 기술을 적용할 계획입니다. 복잡하고 방대한 분량의 운용 교범과 정비 지침서는 벡터 데이터베이스에 효율적으로 저장되며, 리트리벌 에이전트(Retrieval Agent)와 대형언어모델(LLM) 기반의 응답 시스템을 통해 현장에서 필요한 정보를 즉시 찾아 활용할 수 있는 지능형 지원 체계를 구현합니다. 이는 곧 승조원들이 장비 운용 및 정비에 대한 궁금증을 AI참모에게 질문하면, AI가 학습된 방대한 데이터를 기반으로 정확하고 신속한 답변을 제공하는 방식으로 작동하게 됩니다. 이러한 기술적 접근은 제한된 환경에서도 AI의 실질적인 활용 가능성을 보여줄 것입니다."
      },
      {
        "title": "핵심 무장 운용, AI가 지원",
        "content": "이번 ‘장비운용 AI참모’ 개발의 또 다른 중요한 목표는 함정의 핵심 무장 체계, 예를 들어 Mk.45 5인치 함포와 같은 무기 시스템의 운용을 AI가 지원하는 것입니다. 복잡한 무기 시스템의 운용 및 정비 절차를 AI가 쉽게 이해하고 전달할 수 있도록 함으로써, 상대적으로 숙련도가 낮은 인원도 무기를 더욱 효율적으로 다룰 수 있는 기반을 마련하는 데 목적이 있습니다. 이는 숙련된 인력 부족 문제를 완화하고, 유사시 즉각적인 임무 수행 능력을 강화하는 데 크게 기여할 수 있습니다. AI 기반의 지원은 실제 훈련이나 작전 상황에서 발생할 수 있는 다양한 변수에 대한 대응 능력을 높이고, 장비 운용 오류를 최소화하여 해군 함정의 전반적인 작전 효율성과 안전성을 향상시킬 것입니다. AI 기술의 적용은 단순히 정보 제공을 넘어, 실제 작전 수행 능력을 향상시키는 방향으로 나아가고 있습니다."
      },
      {
        "title": "AI, 군사 환경 적용의 의미",
        "content": "윤성호 마키나락스 대표는 이번 과제가 네트워크와 자원이 제한된 실제 함정 환경에서 AI의 운용 가능성을 검증한다는 점에서 매우 의미 있다고 강조했습니다. 복잡한 운용 교범과 정비 지침서를 AI가 실시간으로 학습하고 제공함으로써, 현장의 장비 운용 및 관리 능력을 실질적으로 향상시키는 사례를 만들겠다는 포부입니다. 이를 통해 AI의 효용성을 현장에서 직접 체감할 수 있도록 하는 것이 중요하다고 언급했습니다. 이는 AI 기술이 단순히 이론적인 차원을 넘어, 실제 군사 환경이라는 매우 특수하고 까다로운 조건 속에서도 충분히 적용 가능하며, 가시적인 성과를 낼 수 있음을 입증하려는 시도로 볼 수 있습니다. 이러한 군사 분야에서의 AI 적용 성공 사례는 향후 다양한 국방 분야로의 확산을 위한 중요한 발판이 될 것입니다."
      },
      {
        "title": "방산 혁신 기업의 AI 역량",
        "content": "마키나락스는 ‘방산혁신기업 100’에 선정된 62개 기업 중 유일하게 자체 AI 플랫폼을 보유하고 있다는 점에서 주목받고 있습니다. 이는 자체 기술력을 바탕으로 국방 분야의 AI 혁신을 주도할 수 있는 기업임을 시사합니다. 자체 AI 플랫폼 ‘런웨이’는 다양한 산업 분야의 특화된 AI 솔루션을 개발하고 적용하는 데 강점을 가지고 있으며, 이번 해군 함정용 AI참모 개발 프로젝트를 통해 그 역량을 다시 한번 입증할 것으로 기대됩니다. 방산 분야에서 자체 AI 플랫폼을 보유한 기업은 드물기 때문에, 마키나락스의 기술력과 경쟁력은 더욱 부각될 수밖에 없습니다. 앞으로 마키나락스가 이러한 독자적인 AI 기술력을 바탕으로 국방 분야의 첨단화를 얼마나 성공적으로 이끌어갈지 귀추가 주목됩니다."
      },
      {
        "title": "개인적인 생각",
        "content": "마키나락스의 해군 함정 장비 운용 AI참모 개발 소식은 매우 고무적입니다. 4차 산업혁명의 핵심 기술인 AI가 군사 분야, 특히 함정이라는 제한적이고 특수한 환경에 적용된다는 점은 향후 국방 기술 발전의 새로운 지평을 열 것으로 기대됩니다. AI가 복잡한 매뉴얼을 학습하고 실시간 데이터를 반영하여 승조원들의 업무 부담을 줄이고, 무기 시스템 운용까지 지원한다는 것은 작전 효율성과 안전성을 동시에 높이는 혁신적인 시도입니다. 이는 단순한 기술 도입을 넘어, 미래 전장의 필수 요소가 될 AI의 군사적 활용 가능성을 보여주는 중요한 사례가 될 것입니다. 특히, 제한된 자원 환경에서의 AI 운용 가능성을 검증하고 실질적인 효용성을 입증하려는 마키나락스의 전략은 매우 현실적이며, 군 당국에서도 AI 기술의 도입에 대한 긍정적인 인식을 확산시키는 데 기여할 것입니다. 앞으로 이러한 AI 기술이 해군을 넘어 육군, 공군 등 전 군으로 확대 적용될 가능성도 충분하며, 이는 대한민국 국방력 강화에 중요한 전환점이 될 수 있습니다. AI 기반의 지능형 국방 시스템 구축은 단순한 무기 체계의 현대화를 넘어, 인공지능이 국방의 전반적인 의사결정과 작전 수행 능력을 향상시키는 데 기여할 것이라는 전망을 가능하게 합니다."
      }
    ],
    "hashTag": [
      "#마키나락스",
      "#해군1함대",
      "#장비운용AI참모",
      "#방산혁신기업100",
      "#국방통합인공지능플랫폼",
      "#AI플랫폼런웨이",
      "#LLM옵스",
      "#함정운용",
      "#군사AI",
      "#윤성호대표"
    ]
  }
]