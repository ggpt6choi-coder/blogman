[
  {
    "date": "2025-11-01T17:10:00+09:00",
    "title": "앤트그룹, MoE로 효율 7배 향상한 추론 모델 ‘링 2.0’ 제품군 공개",
    "article": "중국의 앤트그룹이 토큰당 연산량을 최소화하면서도 1조 매개변수 규모까지 확장할 수 있는 언어모델을 선보였다.\n앤트그룹은 30일(현지시간) 추론 효율을 극대화한 1조 매개변수급 언어모델 ‘링 2.0(Ling 2.0)’ 시리즈를 온라인 아카이브를 통해 공개했다.\n지난 10월 출시한 1조 매개변수 오픈 소스 모델 ‘링-1T’의 확장 버전이다. 전문가 혼합(MoE) 구조를 기반으로 한 추론 중심의 희소(Sparse) 모델로, 효율성이 핵심이다.\n링 2.0 시리즈는 ▲링 미니 2.0(Ling mini 2.0) ▲링 플래시 2.0(Ling flash 2.0) ▲링 T(Ling 1T) 등 3종으로 구성돼 있다.\n세 모델 모두 동일한 구조적 원리를 바탕으로, 모델 규모가 커지더라도 토큰당 연산량으로 일관된 희소 활성화 비율을 유지하도록 설계돼 있다.\n각 층은 256개의 라우팅 전문가(Experts)와 1개의 공유 전문가로 구성된다. 토큰마다 9개의 전문가(약 3.5%)만 사용, 활성화 비율이 32분의 1밖에 안 된다.\n앤트 그룹은 \"큰 매개변수 풀을 유지하면서 토큰당 네트워크의 일부만 학습하고 제공하기 때문에 동급의 덴스(dense) 모델보다 약 7배의 효율성을 보인다\"라고 강조했다.\n가장 작은 모델인 링 미니 2.0은 총 160억개의 매개변수를 가지고 있으며, 토큰당 약 14억개의 매개변수가 활성화된다. 중간 단계 모델인 링 플래시 2.0은 1000억개 수준의 매개변수를 지니며, 토큰당 약 61억개가 활성화된다.\n가장 큰 모델인 링 1T는 1조개의 매개변수를 보유하고 있으며, 토큰마다 약 500억개의 매개변수가 활성화돼 동작한다.\n모델 아키텍처, 사전학습, 사후학습, 인프라 전반에 걸쳐 일관된 설계 원칙을 적용했다.\n먼저, 아키텍처 측면에서 ‘링 스케일링 법칙(Ling Scaling Laws)’을 기반으로 각 층의 활성화 비율과 전문가 구성을 사전에 예측하고 설계했다. 연구진은 실험용 ‘링 윈드 터널(Ling Wind Tunnel)’을 통해 소형 MoE 모델을 여러개 학습한 뒤, 이를 활용해 대형 모델의 손실과 전문가 균형을 예측함으로써 효율적인 설계를 가능하게 했다.\n사전학습 단계에서는 20조 토큰 이상의 데이터를 투입했으며, 수학과 코드 등 추론 중심 데이터의 비중을 점차 늘려 최종적으로 전체의 절반 수준까지 끌어올렸다. 또 중간 학습 단계에서는 최대 128K 컨텍스트까지 처리할 수 있도록 확장해 장기 추론 능력을 강화했다.\n사후학습에서는 정렬(Alignment) 과정을 기능(Capability) 단계와 선호(Preference) 단계로 나눠 진행했다. ‘분리 미세조정(Decoupled Fine-Tuning)’과 ‘진화형 CoT(Evo-CoT)’를 적용해 모델이 빠른 응답과 깊은 추론을 상황에 맞게 구분하여 수행할 수 있도록 했다.\n인프라 측면에서는 FP8 정밀도 학습을 도입하여 BF16 대비 약 15~40%의 학습 속도 향상을 달성했으며, 이종 파이프라인 병렬처리와 체크포인트 병합 기술을 적용해 1조 매개변수급 모델 학습을 현실화했다.\n연구진은 “링 2.0은 희소 활성화(Sparse Activation)를 추론 목적과 정렬시킴으로써, 지능의 확장성과 효율성을 동시에 실현했다”라고 밝혔다.\n링 2.0 시리즈의 모델과 코드는 허깅페이스와 깃허브에서 다운로드할 수 있다.\n한편, 앤트 그룹은 지난 10월10일 링-1T를 출시한 지 3주 만에 소형과 중형 모델을 추가한 셈이다. 오픈 소스 경쟁에 본격적으로 뛰어든 것으로 볼 수 있다.\n박찬 기자 cpark@aitimes.com",
    "link": "https://www.aitimes.com/news/articleView.html?idxno=203631",
    "type": "AITIMES",
    "newTitle": "앤트그룹 링 2.0 1조 매개변수 AI 모델 공개 효율 7배 향상",
    "newArticle": [
      {
        "title": "앤트그룹 1조 매개변수 모델",
        "content": "중국의 앤트그룹이 1조 매개변수 규모의 언어모델 '링 2.0(Ling 2.0)' 시리즈를 공개하며 AI 기술 발전에 새로운 이정표를 세웠습니다. 이번 링 2.0 시리즈는 기존의 1조 매개변수 오픈 소스 모델 '링-1T'의 확장 버전으로, 특히 토큰당 연산량을 최소화하면서도 방대한 모델 규모를 효율적으로 운영하는 데 초점을 맞추고 있습니다. 이는 AI 모델의 크기가 커질수록 발생하는 계산량 부담을 줄이고, 더 적은 자원으로도 고성능을 발휘할 수 있게 하는 혁신적인 접근 방식입니다. 앤트그룹의 이러한 노력은 AI 기술의 접근성을 높이고, 더 많은 연구자와 개발자들이 거대 언어모델을 활용하여 혁신적인 결과물을 만들어낼 수 있는 기반을 마련할 것으로 기대됩니다. 앤트그룹은 링 2.0 시리즈 공개를 통해 AI 오픈 소스 경쟁에 본격적으로 뛰어들며, 향후 AI 생태계에 지대한 영향을 미칠 것으로 전망됩니다."
      },
      {
        "title": "링 2.0 효율성의 비밀",
        "content": "앤트그룹의 링 2.0 시리즈는 전문가 혼합(MoE) 구조를 기반으로 한 희소(Sparse) 모델로, 그 효율성이 핵심입니다. 각 층에 256개의 라우팅 전문가와 1개의 공유 전문가를 배치하고, 토큰당 약 3.5%에 해당하는 9개의 전문가만 사용하도록 설계함으로써, 전체 모델 매개변수 대비 실제 활성화되는 비율을 획기적으로 낮췄습니다. 이러한 희소 활성화 메커니즘 덕분에 링 2.0 시리즈는 동급의 덴스(dense) 모델보다 약 7배의 높은 효율성을 자랑합니다. 이는 곧 더 빠른 추론 속도와 더 적은 연산량으로 동일하거나 더 나은 성능을 달성할 수 있음을 의미하며, 앤트그룹이 강조하는 '지능의 확장성과 효율성의 동시 실현'이라는 목표를 명확히 보여줍니다. 이러한 효율성은 AI 모델의 상용화와 대중화를 가속화하는 데 중요한 역할을 할 것입니다."
      },
      {
        "title": "링 2.0 모델 라인업",
        "content": "링 2.0 시리즈는 사용자의 다양한 요구를 충족시키기 위해 세 가지 모델로 구성됩니다. 가장 작은 모델인 '링 미니 2.0'은 총 160억 개의 매개변수를 가지며, 토큰당 약 14억 개의 매개변수가 활성화됩니다. 중간 규모 모델인 '링 플래시 2.0'은 1000억 개 수준의 매개변수를 보유하고, 토큰당 약 61억 개가 활성화됩니다. 가장 강력한 성능을 자랑하는 '링 1T'는 1조 개에 달하는 매개변수를 갖추고 있으며, 토큰마다 약 500억 개의 매개변수가 활성화되어 동작합니다. 이들 세 모델은 모두 동일한 구조적 원리를 따르면서도, 모델 규모가 커져도 토큰당 연산량으로 일관된 희소 활성화 비율을 유지하도록 설계되었습니다. 이를 통해 사용자들은 필요에 맞는 모델을 선택하여 앤트그룹의 혁신적인 AI 기술을 활용할 수 있습니다. 링 2.0 시리즈는 허깅페이스와 깃허브를 통해 공개되어 누구나 접근하고 활용할 수 있습니다."
      },
      {
        "title": "AI 모델 설계의 혁신",
        "content": "앤트그룹의 링 2.0 시리즈는 모델 아키텍처, 사전학습, 사후학습, 그리고 인프라 구축에 이르기까지 전반에 걸쳐 일관된 설계 원칙을 적용했습니다. 특히 아키텍처 설계에서는 '링 스케일링 법칙'을 기반으로 각 층의 활성화 비율과 전문가 구성을 사전에 예측하고 최적화했습니다. 연구진은 '링 윈드 터널'이라는 실험 환경을 통해 소형 MoE 모델을 반복적으로 학습시키고 그 결과를 분석하여 대형 모델의 성능과 효율성을 예측했습니다. 이러한 과정을 통해 대규모 모델에서도 최적의 성능을 유지할 수 있는 기반을 마련했습니다. 사전학습 단계에서는 20조 토큰 이상의 방대한 데이터를 활용했으며, 수학 및 코드와 같은 추론 중심 데이터의 비중을 높여 모델의 핵심 역량을 강화했습니다. 또한, 128K 컨텍스트까지 처리 가능한 장기 추론 능력을 확보하여 더욱 복잡하고 정교한 과제 수행이 가능하도록 설계되었습니다. 앤트그룹의 이러한 체계적인 접근 방식은 AI 모델의 성능과 효율성을 극대화하는 중요한 요인입니다."
      },
      {
        "title": "사후 학습 및 인프라 기술",
        "content": "링 2.0 시리즈는 정교한 사후 학습(Fine-tuning) 과정을 통해 모델의 성능을 한층 더 끌어올렸습니다. 정렬(Alignment) 과정을 기능(Capability) 단계와 선호(Preference) 단계로 나누어 진행했으며, '분리 미세조정(Decoupled Fine-Tuning)'과 '진화형 CoT(Evo-CoT)' 기술을 적용했습니다. 이를 통해 모델은 상황에 따라 빠른 응답과 깊은 추론을 구분하여 수행할 수 있게 되어, 다양한 사용자 요구에 더욱 효과적으로 대응할 수 있습니다. 인프라 측면에서도 괄목할 만한 기술적 진보를 이루었습니다. FP8 정밀도 학습을 도입하여 기존 BF16 대비 학습 속도를 15~40% 향상시켰으며, 이종 파이프라인 병렬처리 및 체크포인트 병합 기술을 효과적으로 활용하여 1조 매개변수급 대규모 모델 학습을 현실화했습니다. 이러한 기술적 혁신들은 앤트그룹이 AI 기술의 한계를 뛰어넘고, 더욱 강력하고 효율적인 언어 모델을 개발할 수 있는 원동력이 되었습니다."
      },
      {
        "title": "오픈 소스 경쟁 가속화",
        "content": "앤트그룹은 지난 10월 '링-1T'를 출시한 지 불과 3주 만에 소형 및 중형 모델인 '링 미니 2.0'과 '링 플래시 2.0'을 추가로 공개하며 오픈 소스 AI 경쟁에 본격적으로 뛰어들었습니다. 이는 AI 기술의 민주화를 촉진하고, 전 세계 개발자 커뮤니티의 혁신을 가속화할 것으로 기대됩니다. 앤트그룹이 공개한 링 2.0 시리즈의 모델과 코드는 허깅페이스와 깃허브에서 누구나 자유롭게 다운로드하여 활용할 수 있습니다. 이러한 개방적인 정책은 AI 연구 및 개발의 장벽을 낮추고, 다양한 응용 분야에서 새로운 가능성을 탐색하는 데 크게 기여할 것입니다. 앤트그룹의 이번 행보는 AI 산업 전반에 걸쳐 기술 공유와 협력의 중요성을 다시 한번 강조하며, 향후 AI 생태계의 발전 방향에 중요한 전환점이 될 수 있습니다. AI 기술의 빠른 발전 속도 속에서 앤트그룹의 지속적인 오픈 소스 기여가 주목되는 이유입니다."
      },
      {
        "title": "개인적인 생각",
        "content": "앤트그룹의 1조 매개변수급 언어모델 '링 2.0' 시리즈 공개는 AI 기술의 발전 방향에 대한 중요한 시사점을 던져줍니다. 특히 토큰당 연산량을 최소화하면서도 모델 규모를 확장하는 희소 활성화(Sparse Activation) 기술은 AI 모델의 효율성을 극대화하는 핵심 전략으로 자리매김할 가능성이 높습니다. 이는 AI 기술의 상용화와 대중화를 가속화하는 데 결정적인 역할을 할 것입니다. AI 모델의 크기와 성능은 비례한다는 기존의 통념을 깨고, 혁신적인 아키텍처와 학습 방법을 통해 효율성과 성능을 동시에 잡으려는 앤트그룹의 노력은 매우 고무적입니다. 또한, 링 2.0 시리즈를 오픈 소스로 공개함으로써 AI 기술 접근성을 높이고, 전 세계 개발자 커뮤니티의 혁신을 촉진하려는 시도는 AI 생태계 발전에 긍정적인 영향을 미칠 것으로 보입니다. 앞으로 앤트그룹과 같은 기업들이 AI 기술의 발전과 함께 사회적 책임감을 가지고 기술을 공유하고 발전시켜 나간다면, AI는 인류에게 더욱 풍요로운 미래를 가져다줄 것입니다. AI 기술의 지속적인 발전과 함께 윤리적이고 책임감 있는 활용 방안에 대한 논의도 병행되어야 할 것입니다. 링 2.0과 같은 혁신적인 AI 모델들이 가져올 미래를 기대하며, 동시에 발생할 수 있는 문제점에 대한 깊이 있는 성찰도 필요합니다."
      }
    ],
    "hashTag": [
      "#앤트그룹",
      "#링2.0",
      "#거대언어모델",
      "#AI",
      "#인공지능",
      "#MoE",
      "#희소모델"
    ]
  }
]